{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.6-classifying-newswires.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPv3Umqck6yziz00L/UWOr5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelounb/Deep_learning_book_francois/blob/master/3_6_classifying_newswires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPHXPBQEfQGJ",
        "colab_type": "text"
      },
      "source": [
        "# Classifying newswires: a multi-class classification example\n",
        "\n",
        "This notebook contains the code samples found in Chapter 3, Section 5 of Deep Learning with Python. Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In the previous section we saw how to classify vector inputs into two mutually exclusive classes using a densely-connected neural network. But what happens when you have more than two classes?\n",
        "In this section, we will build a network to classify Reuters newswires into 46 different mutually-exclusive topics. Since we have many classes, this problem is an instance of \"multi-class classification\", and since each data point should be classified into only one category, the problem is more specifically an instance of \"single-label, multi-class classification\". If each data point could have belonged to multiple categories (in our case, topics) then we would be facing a \"multi-label, multi-class classification\" problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9iy8KDJfwPD",
        "colab_type": "text"
      },
      "source": [
        "**The Reuters dataset**\n",
        "\n",
        "We will be working with the Reuters dataset, a set of short newswires and their topics, published by Reuters in 1986. It's a very simple, widely used toy dataset for text classification. There are 46 different topics; some topics are more represented than others, but each topic has at least 10 examples in the training set.\n",
        "Like IMDB and MNIST, the Reuters dataset comes packaged as part of Keras. Let's take a look right away:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9CMIOyIdLZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06ad5b86-8349-446d-f2f0-975b384b5e87"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tCHqDkEf5BT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d86dec29-c362-4555-e740-edd43b56ee11"
      },
      "source": [
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "127Lob0_gDau",
        "colab_type": "text"
      },
      "source": [
        "Like with the IMDB dataset, the argument num_words=10000 restricts the data to the 10,000 most frequently occurring words found in the data.\n",
        "We have 8,982 training examples and 2,246 test examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpaoymhKf-4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "db8c38cb-8724-4e9e-f987-1fe319f3aa09"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq5zvYpGgGm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "037c0b42-3de0-49cb-9bae-f323df30d4aa"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jiib1BCgIrq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa13974a-3a29-488c-aadc-9008275eedd6"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8982,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbb9p47ygME8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "6379f008-af79-439f-a236-705e1f952988"
      },
      "source": [
        "# As with the IMDB reviews, each example is a list of integers (word indices):\n",
        "train_data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]),\n",
              "       list([1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]),\n",
              "       list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12]),\n",
              "       ...,\n",
              "       list([1, 141, 3890, 387, 81, 8, 16, 1629, 10, 340, 1241, 850, 31, 56, 3890, 691, 9, 1241, 71, 9, 5985, 2, 2, 699, 2, 2, 2, 699, 244, 5945, 4, 49, 8, 4, 656, 850, 33, 2993, 9, 2139, 340, 3371, 1493, 9, 2, 22, 2, 1094, 687, 83, 35, 15, 257, 6, 57, 9190, 7, 4, 5956, 654, 5, 2, 6191, 1371, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12]),\n",
              "       list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 3614, 18, 14, 74, 134, 5131, 18, 88, 2321, 72, 11, 14, 1842, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 3237, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 1325, 6, 1532, 142, 971, 6463, 43, 359, 5, 4, 326, 753, 364, 17, 12]),\n",
              "       list([1, 227, 2406, 91, 2, 125, 2855, 21, 4, 3976, 76, 7, 4, 757, 481, 3976, 790, 5259, 5654, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 6917, 1688, 340, 7, 194, 9411, 6, 1894, 21, 127, 2151, 2394, 1456, 6, 3034, 4, 329, 433, 7, 65, 87, 1127, 10, 8219, 1475, 290, 9, 21, 567, 16, 1926, 24, 4, 76, 209, 30, 4033, 6655, 5654, 8, 4, 60, 8, 4, 966, 308, 40, 2575, 129, 2, 295, 277, 1071, 9, 24, 286, 2114, 234, 222, 9, 4, 906, 3994, 8519, 114, 5758, 1752, 7, 4, 113, 17, 12])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mos0fgLzgP7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "59fb486d-52e6-434f-d9f2-b0edd1718bf1"
      },
      "source": [
        "# Here's how you can decode it back to words, in case you are curious:\n",
        "\n",
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# Note that our indices were offset by 3\n",
        "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\"."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ6UFIUPg-O3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randrange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q11k2kybghvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a3a53c0a-dab6-4d3e-98af-f67b7a401613"
      },
      "source": [
        "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[randrange(0,500)]])\n",
        "decoded_newswire"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? shr profit seven cts vs n a net profit 587 000 vs profit 3 231 000 sales 18 5 mln vs 18 7 mln nine mths shr loss 39 ct s vs n a net loss 2 368 000 vs ? 7 165 000 sales 55 4 mln vs 54 2 mln note current nine month figures include extraordinary loss of 1 2 mln dlrs or 17 cts per share resulting from costs associated with restructuring prior quarter and nine month per share figures not applicable because company began operations in october 1986 with the acquisition of gould inc's lt ? medical products group reuter 3\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY6kB7SFhTWB",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the data\n",
        "We can vectorize the data with the exact same code as in our previous example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvDQZ6P9gOoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghC59vDCTY2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XQs7sm5TeEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our vectorized training data\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# Our vectorized test data\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do2t5srtT72q",
        "colab_type": "text"
      },
      "source": [
        "To vectorize the labels, there are two possibilities: we could just cast the label list as an integer tensor, or we could use a \"one-hot\" encoding. One-hot encoding is a widely used format for categorical data, also called \"categorical encoding\". For a more detailed explanation of one-hot encoding, you can refer to Chapter 6, Section 1. In our case, one-hot encoding of our labels consists in embedding each label as an all-zero vector with a 1 in the place of the label index, e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikt1uwQoT2_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7su4YYP5UJ1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b28757d-0d84-451b-ea82-48a7826a9892"
      },
      "source": [
        "only_2test_label = np.array([3,3,1,2,3,1,1,0,0,4])\n",
        "only_2test_label"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 1, 2, 3, 1, 1, 0, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWMrwIbGU5cq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "b4cd09f6-787d-48c1-80bd-2b3a0f3988d9"
      },
      "source": [
        "only_2test_one_hot_label = to_one_hot(only_2test_label, 5)  # The number 5 here sets the dimension to 5 (from 0 to 4). Default is 46\n",
        "only_2test_one_hot_label"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6MvaUH3UN3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our vectorized training labels\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "# Our vectorized test labels\n",
        "one_hot_test_labels = to_one_hot(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq1cm5DOVuxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}